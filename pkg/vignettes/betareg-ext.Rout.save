
> options(width = 70, prompt = "R> ", continue = "+  ", 
+     useFancyQuotes = FALSE)

> library("betareg")
Loading required package: Formula

> combine <- function(x, sep, width) {
+     cs <- cumsum(nchar(x))
+     remaining <- if (any(cs[-1] > width)) 
+         combine(x[c(FALSE, cs[-1] > .... [TRUNCATED] 

> prettyPrint <- function(x, sep = " ", linebreak = "\n\t", 
+     width = getOption("width")) {
+     x <- strsplit(x, sep)[[1]]
+     paste(combine( .... [TRUNCATED] 

> cache <- FALSE

> enumerate <- function(x) paste(paste(x[-length(x)], 
+     collapse = ", "), x[length(x)], sep = " and ")

> betamix_methods <- enumerate(paste("\\\\fct{", gsub("\\.betamix", 
+     "", as.character(methods(class = "betamix"))), "}", sep = ""))

> cat(prettyPrint(prompt(extraComponent, filename = NA)$usage[[2]], 
+     sep = ", ", linebreak = paste("\n", paste(rep(" ", 2), collapse = ""), 
+   .... [TRUNCATED] 
extraComponent(type = c("uniform", "betareg"), coef, delta,  
  link = "logit", link.phi = "log")
> data("ReadingSkills", package = "betareg")

> mean_accuracy <- format(round(with(ReadingSkills, 
+     tapply(accuracy, dyslexia, mean)), digits = 3), nsmall = 3)

> mean_iq <- format(round(with(ReadingSkills, tapply(iq, 
+     dyslexia, mean)), digits = 3), nsmall = 3)

> data("ReadingSkills", package = "betareg")

> rs_ols <- lm(qlogis(accuracy) ~ dyslexia * iq, data = ReadingSkills)

> rs_beta <- betareg(accuracy ~ dyslexia * iq | dyslexia + 
+     iq, data = ReadingSkills, hessian = TRUE)

> cl1 <- hcl(c(260, 0), 90, 40)

> cl2 <- hcl(c(260, 0), 10, 95)

> plot(accuracy ~ iq, data = ReadingSkills, col = cl2[as.numeric(dyslexia)], 
+     main = "Reading skills data", xlab = "IQ score", ylab = "Reading a ..." ... [TRUNCATED] 

> points(accuracy ~ iq, data = ReadingSkills, cex = 1.5, 
+     pch = (1:2)[as.numeric(dyslexia)], col = cl1[as.numeric(dyslexia)])

> nd <- data.frame(dyslexia = "no", iq = -30:30/10)

> lines(nd$iq, predict(rs_beta, nd), col = cl1[1], lwd = 2)

> lines(nd$iq, plogis(predict(rs_ols, nd)), col = cl1[1], 
+     lty = 2, lwd = 2)

> nd <- data.frame(dyslexia = "yes", iq = -30:30/10)

> lines(nd$iq, predict(rs_beta, nd), col = cl1[2], lwd = 2)

> lines(nd$iq, plogis(predict(rs_ols, nd)), col = cl1[2], 
+     lty = 2, lwd = 2)

> legend("topleft", c("control", "dyslexic", "betareg", 
+     "lm"), lty = c(NA, NA, 1:2), pch = c(19, 17, NA, NA), lwd = 2, 
+     col = c(cl2, 1, 1 .... [TRUNCATED] 

> legend("topleft", c("control", "dyslexic", "betareg", 
+     "lm"), lty = c(NA, NA, 1:2), pch = c(1, 2, NA, NA), col = c(cl1, 
+     NA, NA), bty =  .... [TRUNCATED] 

> data("ReadingSkills", package = "betareg")

> rs_f <- accuracy ~ dyslexia * iq | dyslexia * iq

> rs_ml <- betareg(rs_f, data = ReadingSkills, type = "ML")

> rs_bc <- betareg(rs_f, data = ReadingSkills, type = "BC")

> rs_br <- betareg(rs_f, data = ReadingSkills, type = "BR")

> rs_list <- list(rs_ml, rs_bc, rs_br)

> cf <- paste("$", format(round(sapply(rs_list, coef), 
+     digits = 3), nsmall = 3), "$\\phantom{)}", sep = "")

> se <- paste("(", format(round(sapply(rs_list, function(x) sqrt(diag(vcov(x)))), 
+     digits = 3), nsmall = 3), ")", sep = "")

> ll <- paste("$", format(round(sapply(rs_list, logLik), 
+     digits = 3), nsmall = 3), "$\\phantom{)}", sep = "")

> cfse <- matrix(as.vector(rbind(cf, se)), ncol = 3)

> cfse <- cbind(c("Mean", rep("", 7), "Precision", rep("", 
+     7)), rep(as.vector(rbind(c("(Intercept)", "\\code{dyslexia}", 
+     "\\code{iq}", " ..." ... [TRUNCATED] 

> cfse <- rbind(cfse, c("Log-likelihood", "", ll[1:2], 
+     paste(ll[3], "\\\\ \\hline")))

> writeLines(apply(cfse, 1, paste, collapse = " & "))
Mean & (Intercept) & $ 1.019$\phantom{)} & $ 0.990$\phantom{)} & $ 0.985$\phantom{)} \\
 &  & (0.145) & (0.150) & (0.150) \\
 & \code{dyslexia} & $-0.638$\phantom{)} & $-0.610$\phantom{)} & $-0.603$\phantom{)} \\
 &  & (0.145) & (0.150) & (0.150) \\
 & \code{iq} & $ 0.690$\phantom{)} & $ 0.700$\phantom{)} & $ 0.707$\phantom{)} \\
 &  & (0.127) & (0.133) & (0.133) \\
 & \code{dyslexia:iq} & $-0.776$\phantom{)} & $-0.786$\phantom{)} & $-0.784$\phantom{)} \\
 &  & (0.127) & (0.133) & (0.133) \\ \hline
Precision & (Intercept) & $ 3.040$\phantom{)} & $ 2.811$\phantom{)} & $ 2.721$\phantom{)} \\
 &  & (0.258) & (0.257) & (0.256) \\
 & \code{dyslexia} & $ 1.768$\phantom{)} & $ 1.705$\phantom{)} & $ 1.634$\phantom{)} \\
 &  & (0.258) & (0.257) & (0.256) \\
 & \code{iq} & $ 1.437$\phantom{)} & $ 1.370$\phantom{)} & $ 1.281$\phantom{)} \\
 &  & (0.257) & (0.257) & (0.257) \\
 & \code{dyslexia:iq} & $-0.611$\phantom{)} & $-0.668$\phantom{)} & $-0.759$\phantom{)} \\
 &  & (0.257) & (0.257) & (0.257) \\ \hline
Log-likelihood &  & $66.734$\phantom{)} & $66.334$\phantom{)} & $66.134$\phantom{)} \\ \hline

> pr_phi <- sapply(list(`Maximum likelihood` = rs_ml, 
+     `Bias correction` = rs_bc, `Bias reduction` = rs_br), predict, 
+     type = "precision")

> pairs(log(pr_phi), panel = function(x, y, ...) {
+     panel.smooth(x, y, ...)
+     abline(0, 1, lty = 2)
+ })

> set.seed(1071)

> n <- nrow(ReadingSkills)

> ReadingSkills$x1 <- rnorm(n)

> ReadingSkills$x2 <- runif(n)

> ReadingSkills$x3 <- factor(sample(0:1, n, replace = TRUE))

> if (cache & file.exists("betareg-ext-betatree.rda")) {
+     load("betareg-ext-betatree.rda")
+ } else {
+     rs_tree <- betatree(accuracy ~ iq | i .... [TRUNCATED] 
Loading required package: party
Loading required package: survival
Loading required package: splines
Loading required package: grid
Loading required package: modeltools
Loading required package: stats4
Loading required package: coin
Loading required package: mvtnorm
Loading required package: zoo

Attaching package: 'zoo'

The following object(s) are masked from 'package:base':

    as.Date, as.Date.numeric

Loading required package: sandwich
Loading required package: strucchange
Loading required package: vcd
Loading required package: MASS
Loading required package: colorspace

> plot(rs_tree)

> plot(rs_tree)

> coef(rs_tree)
  (Intercept)          iq (phi)_(Intercept)  (phi)_iq
2   1.6565251  1.46570751          1.272597 2.0478578
3   0.3809322 -0.08622808          4.807662 0.8260329

> rs_tree
1) dyslexia == {no}; criterion = 0.999, statistic = 22.687
  2)*  weights = 25 
Terminal node model
betaReg fit with coefficients:
      (Intercept)                 iq  (phi)_(Intercept)  
            1.657              1.466              1.273  
         (phi)_iq  
            2.048  

1) dyslexia == {yes}
  3)*  weights = 19 
Terminal node model
betaReg fit with coefficients:
      (Intercept)                 iq  (phi)_(Intercept)  
          0.38093           -0.08623            4.80766  
         (phi)_iq  
          0.82603  


> sctest(rs_tree)
$`1`
              dyslexia        x1       x2        x3
statistic 2.268741e+01 8.5250962 5.569861 3.6273300
p.value   5.847856e-04 0.9094631 0.998710 0.9142006

$`2`
          dyslexia        x1        x2        x3
statistic        0 6.4116324 4.5170190 8.2019125
p.value         NA 0.8412097 0.9751644 0.2325712

$`3`
          [,1]
statistic    0
p.value      1


> if (cache & file.exists("betareg-ext-betamix.rda")) {
+     load("betareg-ext-betamix.rda")
+ } else {
+     rs_mix <- betamix(accuracy ~ iq, data = .... [TRUNCATED] 
Loading required package: flexmix
Loading required package: lattice
Loading required package: multcomp

> rs_mix

Call:
betamix(formula = accuracy ~ iq, data = ReadingSkills, 
    k = 3, nstart = 10, extra_components = extraComponent(type = "uniform", 
        coef = 0.99, delta = 0.01))

Cluster sizes:
 1  2  3 
20 10 14 

convergence after 48 iterations

> summary(rs_mix)
$Comp.1
$Comp.1$mean
             Estimate Std. Error z value  Pr(>|z|)    
(Intercept)  0.502437   0.083207  6.0384 1.556e-09 ***
iq          -0.047179   0.114318 -0.4127    0.6798    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

$Comp.1$precision
            Estimate Std. Error z value  Pr(>|z|)    
(Intercept)  4.23880    0.75975  5.5792 2.416e-08 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 


$Comp.2
$Comp.2$mean
            Estimate Std. Error z value  Pr(>|z|)    
(Intercept)  1.40568    0.26828  5.2396 1.609e-07 ***
iq           0.82554    0.21693  3.8056 0.0001415 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

$Comp.2$precision
            Estimate Std. Error z value  Pr(>|z|)    
(Intercept)  2.68629    0.45765  5.8697 4.366e-09 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 



> par(mfrow = c(1, 2))

> ix <- as.numeric(ReadingSkills$dyslexia)

> prob <- 2 * (posterior(rs_mix)[cbind(seq_along(ix), 
+     clusters(rs_mix))] - 0.5)

> col3 <- hcl(c(0, 260, 130), 65, 45, fixup = FALSE)

> col1 <- col3[clusters(rs_mix)]

> col2 <- hcl(c(0, 260, 130)[clusters(rs_mix)], 65 * 
+     abs(prob)^1.5, 95 - 50 * abs(prob)^1.5, fixup = FALSE)

> plot(accuracy ~ iq, data = ReadingSkills, col = col2, 
+     pch = 19, cex = 1.5, xlim = c(-2, 2), main = "Mixture model (dyslexia unobserved)")

> points(accuracy ~ iq, data = ReadingSkills, cex = 1.5, 
+     pch = 1, col = col1)

> iq <- -30:30/10

> cf <- rbind(coef(rs_mix, model = "mean", component = 1:2), 
+     c(qlogis(0.99), 0))

> for (i in 1:3) lines(iq, plogis(cf[i, 1] + cf[i, 2] * 
+     iq), lwd = 2, col = col3[i])

> ix <- as.numeric(ReadingSkills$dyslexia)

> col1 <- hcl(c(260, 0), 90, 40)[ix]

> col2 <- hcl(c(260, 0), 10, 95)[ix]

> plot(accuracy ~ iq, data = ReadingSkills, col = col2, 
+     pch = 19, cex = 1.5, xlim = c(-2, 2), main = "Partitioned model (dyslexia observed)")

> points(accuracy ~ iq, data = ReadingSkills, cex = 1.5, 
+     pch = 1, col = col1)

> cf <- coef(rs_tree, model = "mean")

> col3 <- hcl(c(260, 0), 90, 40)

> for (i in 1:2) lines(iq, plogis(cf[i, 1] + cf[i, 2] * 
+     iq), lwd = 2, col = col3[i])

> table(clusters(rs_mix), ReadingSkills$dyslexia)
   
    no yes
  1  4  16
  2  7   3
  3 14   0

> data("GasolineYield", package = "betareg")

> gy <- lapply(c("ML", "BC", "BR"), function(x) betareg(yield ~ 
+     batch + temp, data = GasolineYield, type = x))

> cf <- matrix(paste("$", format(round(sapply(gy, coef), 
+     digits = 5), nsmall = 5), "$\\phantom{)}", sep = ""), ncol = 3)

> se <- matrix(gsub(" ", "", paste("(", format(round(sapply(gy, 
+     function(x) sqrt(diag(vcov(x)))), digits = 5), nsmall = 5), 
+     ")", sep = " ..." ... [TRUNCATED] 

> cfse <- cbind(cf[, 1], se[, 1], cf[, 2], se[, 2], 
+     cf[, 3], se[, 3])

> cfse <- cbind(c(paste("$\\beta_{", 1:11, "}$", sep = ""), 
+     "$\\phi$"), cfse[, 1:5], paste(cfse[, 6], c(rep("\\\\", 11), 
+     "\\\\ \\hline") .... [TRUNCATED] 

> writeLines(apply(cfse, 1, paste, collapse = " & "))
$\beta_{1}$ & $ -6.15957$\phantom{)} & (0.18232) & $ -6.14837$\phantom{)} & (0.23595) & $ -6.14171$\phantom{)} & (0.23588) \\
$\beta_{2}$ & $  1.72773$\phantom{)} & (0.10123) & $  1.72484$\phantom{)} & (0.13107) & $  1.72325$\phantom{)} & (0.13106) \\
$\beta_{3}$ & $  1.32260$\phantom{)} & (0.11790) & $  1.32009$\phantom{)} & (0.15260) & $  1.31860$\phantom{)} & (0.15257) \\
$\beta_{4}$ & $  1.57231$\phantom{)} & (0.11610) & $  1.56928$\phantom{)} & (0.15030) & $  1.56734$\phantom{)} & (0.15028) \\
$\beta_{5}$ & $  1.05971$\phantom{)} & (0.10236) & $  1.05788$\phantom{)} & (0.13251) & $  1.05677$\phantom{)} & (0.13249) \\
$\beta_{6}$ & $  1.13375$\phantom{)} & (0.10352) & $  1.13165$\phantom{)} & (0.13404) & $  1.13024$\phantom{)} & (0.13403) \\
$\beta_{7}$ & $  1.04016$\phantom{)} & (0.10604) & $  1.03829$\phantom{)} & (0.13729) & $  1.03714$\phantom{)} & (0.13727) \\
$\beta_{8}$ & $  0.54369$\phantom{)} & (0.10913) & $  0.54309$\phantom{)} & (0.14119) & $  0.54242$\phantom{)} & (0.14116) \\
$\beta_{9}$ & $  0.49590$\phantom{)} & (0.10893) & $  0.49518$\phantom{)} & (0.14099) & $  0.49446$\phantom{)} & (0.14096) \\
$\beta_{10}$ & $  0.38579$\phantom{)} & (0.11859) & $  0.38502$\phantom{)} & (0.15353) & $  0.38459$\phantom{)} & (0.15351) \\
$\beta_{11}$ & $  0.01097$\phantom{)} & (0.00041) & $  0.01094$\phantom{)} & (0.00053) & $  0.01093$\phantom{)} & (0.00053) \\
$\phi$ & $440.27839$\phantom{)} & (110.02562) & $261.20610$\phantom{)} & (65.25866) & $261.03777$\phantom{)} & (65.21640) \\ \hline

> sapply(gy, coef, model = "precision")
   (phi)    (phi)    (phi) 
440.2784 261.2061 261.0378 

> sapply(gy, logLik)
[1] 84.79756 82.94707 82.94499

> data("GasolineYield", package = "betareg")

> gy2 <- lapply(c("ML", "BC", "BR"), function(x) betareg(yield ~ 
+     batch + temp | 1, data = GasolineYield, type = x))

> sapply(gy2, logLik)
[1] 84.79756 83.79707 83.26777

> cf <- matrix(paste("$", format(round(sapply(gy2, coef), 
+     digits = 5), nsmall = 5), "$\\phantom{)}", sep = ""), ncol = 3)

> se <- matrix(gsub(" ", "", paste("(", format(round(sapply(gy2, 
+     function(x) sqrt(diag(vcov(x)))), digits = 5), nsmall = 5), 
+     ")", sep =  .... [TRUNCATED] 

> cfse <- cbind(cf[, 1], se[, 1], cf[, 2], se[, 2], 
+     cf[, 3], se[, 3])

> cfse <- cbind(c(paste("$\\beta_{", 1:11, "}$", sep = ""), 
+     "$\\log\\phi$"), cfse[, 1:5], paste(cfse[, 6], c(rep("\\\\", 
+     11), "\\\\ \\hl ..." ... [TRUNCATED] 

> writeLines(apply(cfse, 1, paste, collapse = " & "))
$\beta_{1}$ & $-6.15957$\phantom{)} & (0.18232) & $-6.14837$\phantom{)} & (0.21944) & $-6.14259$\phantom{)} & (0.22998) \\
$\beta_{2}$ & $ 1.72773$\phantom{)} & (0.10123) & $ 1.72484$\phantom{)} & (0.12189) & $ 1.72347$\phantom{)} & (0.12777) \\
$\beta_{3}$ & $ 1.32260$\phantom{)} & (0.11790) & $ 1.32009$\phantom{)} & (0.14193) & $ 1.31880$\phantom{)} & (0.14875) \\
$\beta_{4}$ & $ 1.57231$\phantom{)} & (0.11610) & $ 1.56928$\phantom{)} & (0.13978) & $ 1.56758$\phantom{)} & (0.14651) \\
$\beta_{5}$ & $ 1.05971$\phantom{)} & (0.10236) & $ 1.05788$\phantom{)} & (0.12323) & $ 1.05691$\phantom{)} & (0.12917) \\
$\beta_{6}$ & $ 1.13375$\phantom{)} & (0.10352) & $ 1.13165$\phantom{)} & (0.12465) & $ 1.13041$\phantom{)} & (0.13067) \\
$\beta_{7}$ & $ 1.04016$\phantom{)} & (0.10604) & $ 1.03829$\phantom{)} & (0.12767) & $ 1.03729$\phantom{)} & (0.13383) \\
$\beta_{8}$ & $ 0.54369$\phantom{)} & (0.10913) & $ 0.54309$\phantom{)} & (0.13133) & $ 0.54248$\phantom{)} & (0.13763) \\
$\beta_{9}$ & $ 0.49590$\phantom{)} & (0.10893) & $ 0.49518$\phantom{)} & (0.13112) & $ 0.49453$\phantom{)} & (0.13743) \\
$\beta_{10}$ & $ 0.38579$\phantom{)} & (0.11859) & $ 0.38502$\phantom{)} & (0.14278) & $ 0.38465$\phantom{)} & (0.14966) \\
$\beta_{11}$ & $ 0.01097$\phantom{)} & (0.00041) & $ 0.01094$\phantom{)} & (0.00050) & $ 0.01093$\phantom{)} & (0.00052) \\
$\log\phi$ & $ 6.08741$\phantom{)} & (0.24990) & $ 5.71191$\phantom{)} & (0.24986) & $ 5.61608$\phantom{)} & (0.24984) \\ \hline

 *** Run successfully completed ***
> proc.time()
   user  system elapsed 
 22.925   0.112  23.119 
