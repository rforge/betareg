
R version 3.0.0 (2013-04-03) -- "Masked Marvel"
Copyright (C) 2013 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> pkgname <- "betareg"
> source(file.path(R.home("share"), "R", "examples-header.R"))
> options(warn = 1)
> library('betareg')
Loading required package: Formula
> 
> base::assign(".oldSearch", base::search(), pos = 'CheckExEnv')
> cleanEx()
> nameEx("CarTask")
> ### * CarTask
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: CarTask
> ### Title: Partition-primed Probability Judgement Task for Car Dealership
> ### Aliases: CarTask
> ### Keywords: datasets
> 
> ### ** Examples
> 
> data("CarTask", package = "betareg")
> car_betamix <- betamix(probability ~ 1, data = CarTask, k = 3,
+   extra_components = list(extraComponent(type = "uniform", coef = 1/2,
+   delta = 0.01), extraComponent(type = "uniform", coef = 1/4, delta = 0.01)),
+   FLXconcomitant = FLXPmultinom(~ task))
Loading required package: flexmix
Loading required package: lattice
> 
> 
> 
> cleanEx()

detaching 'package:flexmix', 'package:lattice'

> nameEx("FoodExpenditure")
> ### * FoodExpenditure
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: FoodExpenditure
> ### Title: Proportion of Household Income Spent on Food
> ### Aliases: FoodExpenditure
> ### Keywords: datasets
> 
> ### ** Examples
> 
> data("FoodExpenditure", package = "betareg")
> 
> ## Ferrari and Cribari-Neto (2004)
> ## Section 4
> fe_lin <- lm(I(food/income) ~ income + persons, data = FoodExpenditure)
> library("lmtest")
Loading required package: zoo

Attaching package: 'zoo'

The following object is masked from 'package:base':

    as.Date, as.Date.numeric

> bptest(fe_lin)

	studentized Breusch-Pagan test

data:  fe_lin
BP = 5.9348, df = 2, p-value = 0.05144

> 
> ## Table 2
> fe_beta <- betareg(I(food/income) ~ income + persons, data = FoodExpenditure)
> summary(fe_beta)

Call:
betareg(formula = I(food/income) ~ income + persons, data = FoodExpenditure)

Standardized weighted residuals 2:
    Min      1Q  Median      3Q     Max 
-2.7818 -0.4445  0.2024  0.6852  1.8755 

Coefficients (mean model with logit link):
             Estimate Std. Error z value Pr(>|z|)    
(Intercept) -0.622548   0.223854  -2.781 0.005418 ** 
income      -0.012299   0.003036  -4.052 5.09e-05 ***
persons      0.118462   0.035341   3.352 0.000802 ***

Phi coefficients (precision model with identity link):
      Estimate Std. Error z value Pr(>|z|)    
(phi)    35.61       8.08   4.407 1.05e-05 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Type of estimator: ML (maximum likelihood)
Log-likelihood: 45.33 on 4 Df
Pseudo R-squared: 0.3878
Number of iterations: 28 (BFGS) + 4 (Fisher scoring) 
> 
> 
> 
> cleanEx()

detaching 'package:lmtest', 'package:zoo'

> nameEx("GasolineYield")
> ### * GasolineYield
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: GasolineYield
> ### Title: Estimation of Gasoline Yields from Crude Oil
> ### Aliases: GasolineYield
> ### Keywords: datasets
> 
> ### ** Examples
> 
> data("GasolineYield", package = "betareg")
> 
> gy1 <- betareg(yield ~ gravity + pressure + temp10 + temp, data = GasolineYield)
> summary(gy1)

Call:
betareg(formula = yield ~ gravity + pressure + temp10 + temp, data = GasolineYield)

Standardized weighted residuals 2:
    Min      1Q  Median      3Q     Max 
-2.1189 -0.6985 -0.0088  0.6306  2.1572 

Coefficients (mean model with logit link):
              Estimate Std. Error z value Pr(>|z|)    
(Intercept) -2.6949422  0.7625693  -3.534 0.000409 ***
gravity      0.0045412  0.0071419   0.636 0.524871    
pressure     0.0304135  0.0281007   1.082 0.279117    
temp10      -0.0110449  0.0022640  -4.879 1.07e-06 ***
temp         0.0105650  0.0005154  20.499  < 2e-16 ***

Phi coefficients (precision model with identity link):
      Estimate Std. Error z value Pr(>|z|)    
(phi)   248.24      62.02   4.003 6.26e-05 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Type of estimator: ML (maximum likelihood)
Log-likelihood: 75.68 on 6 Df
Pseudo R-squared: 0.9398
Number of iterations: 144 (BFGS) + 5 (Fisher scoring) 
> 
> ## Ferrari and Cribari-Neto (2004)
> gy2 <- betareg(yield ~ batch + temp, data = GasolineYield)
> ## Table 1
> summary(gy2)

Call:
betareg(formula = yield ~ batch + temp, data = GasolineYield)

Standardized weighted residuals 2:
    Min      1Q  Median      3Q     Max 
-2.8750 -0.8149  0.1601  0.8384  2.0483 

Coefficients (mean model with logit link):
              Estimate Std. Error z value Pr(>|z|)    
(Intercept) -6.1595710  0.1823247 -33.784  < 2e-16 ***
batch1       1.7277289  0.1012294  17.067  < 2e-16 ***
batch2       1.3225969  0.1179020  11.218  < 2e-16 ***
batch3       1.5723099  0.1161045  13.542  < 2e-16 ***
batch4       1.0597141  0.1023598  10.353  < 2e-16 ***
batch5       1.1337518  0.1035232  10.952  < 2e-16 ***
batch6       1.0401618  0.1060365   9.809  < 2e-16 ***
batch7       0.5436922  0.1091275   4.982 6.29e-07 ***
batch8       0.4959007  0.1089257   4.553 5.30e-06 ***
batch9       0.3857930  0.1185933   3.253  0.00114 ** 
temp         0.0109669  0.0004126  26.577  < 2e-16 ***

Phi coefficients (precision model with identity link):
      Estimate Std. Error z value Pr(>|z|)    
(phi)    440.3      110.0   4.002 6.29e-05 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Type of estimator: ML (maximum likelihood)
Log-likelihood:  84.8 on 12 Df
Pseudo R-squared: 0.9617
Number of iterations: 51 (BFGS) + 3 (Fisher scoring) 
> ## Figure 2
> par(mfrow = c(3, 2))
> plot(gy2, which = 1, type = "pearson", sub.caption = "")
> plot(gy2, which = 1, type = "deviance", sub.caption = "")
> plot(gy2, which = 5, type = "deviance", sub.caption = "")
> plot(gy2, which = 4, type = "pearson", sub.caption = "")
> plot(gy2, which = 2:3)
> par(mfrow = c(1, 1))
> 
> ## exclude 4th observation
> gy2a <- update(gy2, subset = -4)
> gy2a

Call:
betareg(formula = yield ~ batch + temp, data = GasolineYield, subset = -4)

Coefficients (mean model with logit link):
(Intercept)       batch1       batch2       batch3       batch4       batch5  
   -6.35647      1.88688      1.37039      1.62512      1.08066      1.15158  
     batch6       batch7       batch8       batch9         temp  
    1.05766      0.56522      0.50066      0.38523      0.01146  

Phi coefficients (precision model with identity link):
(phi)  
577.8  

> summary(gy2a)

Call:
betareg(formula = yield ~ batch + temp, data = GasolineYield, subset = -4)

Standardized weighted residuals 2:
    Min      1Q  Median      3Q     Max 
-2.3747 -1.0482  0.1391  0.8703  2.4165 

Coefficients (mean model with logit link):
              Estimate Std. Error z value Pr(>|z|)    
(Intercept) -6.3564713  0.1716020 -37.042  < 2e-16 ***
batch1       1.8868782  0.1001837  18.834  < 2e-16 ***
batch2       1.3703911  0.1042352  13.147  < 2e-16 ***
batch3       1.6251199  0.1028326  15.804  < 2e-16 ***
batch4       1.0806596  0.0897855  12.036  < 2e-16 ***
batch5       1.1515826  0.0906857  12.699  < 2e-16 ***
batch6       1.0576556  0.0929172  11.383  < 2e-16 ***
batch7       0.5652219  0.0956100   5.912 3.39e-09 ***
batch8       0.5006625  0.0953210   5.252 1.50e-07 ***
batch9       0.3852258  0.1037500   3.713 0.000205 ***
temp         0.0114588  0.0003945  29.050  < 2e-16 ***

Phi coefficients (precision model with identity link):
      Estimate Std. Error z value Pr(>|z|)    
(phi)    577.8      146.7   3.938 8.22e-05 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Type of estimator: ML (maximum likelihood)
Log-likelihood: 86.62 on 12 Df
Pseudo R-squared: 0.9662
Number of iterations: 51 (BFGS) + 4 (Fisher scoring) 
> 
> 
> 
> graphics::par(get("par.postscript", pos = 'CheckExEnv'))
> cleanEx()
> nameEx("ImpreciseTask")
> ### * ImpreciseTask
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: ImpreciseTask
> ### Title: Imprecise Probabilities for Sunday Weather and Boeing Stock Task
> ### Aliases: ImpreciseTask
> ### Keywords: datasets
> 
> ### ** Examples
> 
> data("ImpreciseTask", package = "betareg")
> wt_betamix <- betamix(location ~ difference * task, data = ImpreciseTask, k = 2,
+   extra_components = extraComponent(type = "betareg", coef =
+     list(mean = 0, precision = 8)),
+   FLXconcomitant = FLXPmultinom(~ task))
Loading required package: flexmix
Loading required package: lattice
> 
> 
> 
> cleanEx()

detaching 'package:flexmix', 'package:lattice'

> nameEx("MockJurors")
> ### * MockJurors
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: MockJurors
> ### Title: Confidence of Mock Jurors in Their Verdicts
> ### Aliases: MockJurors
> ### Keywords: datasets
> 
> ### ** Examples
> 
> data("MockJurors", package = "betareg")
> library("lmtest")
Loading required package: zoo

Attaching package: 'zoo'

The following object is masked from 'package:base':

    as.Date, as.Date.numeric

> 
> ## Smithson & Verkuilen (2006, Table 1)
> ## variable dispersion model
> ## (NOTE: numerical rather than analytical Hessian is used for replication,
> ##  Smithson & Verkuilen erroneously compute one-sided p-values)
> mj_vd <- betareg(confidence ~ verdict * conflict | verdict * conflict,
+   data = MockJurors, hessian = TRUE)
> summary(mj_vd)

Call:
betareg(formula = confidence ~ verdict * conflict | verdict * conflict, 
    data = MockJurors, hessian = TRUE)

Standardized weighted residuals 2:
    Min      1Q  Median      3Q     Max 
-2.4668 -0.6877 -0.1770  0.4669  3.4217 

Coefficients (mean model with logit link):
                 Estimate Std. Error z value Pr(>|z|)    
(Intercept)      0.912404   0.103979   8.775  < 2e-16 ***
verdict          0.005035   0.103979   0.048  0.96138    
conflict         0.168573   0.103979   1.621  0.10497    
verdict:conflict 0.280010   0.103979   2.693  0.00708 ** 

Phi coefficients (precision model with log link):
                 Estimate Std. Error z value Pr(>|z|)    
(Intercept)        1.1733     0.1278   9.180  < 2e-16 ***
verdict           -0.3299     0.1278  -2.581  0.00985 ** 
conflict           0.2196     0.1278   1.718  0.08576 .  
verdict:conflict   0.3163     0.1278   2.475  0.01334 *  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Type of estimator: ML (maximum likelihood)
Log-likelihood: 40.12 on 8 Df
Pseudo R-squared: 0.03885
Number of iterations in BFGS optimization: 19 
> 
> ## model selection for beta regression: null model, fixed dispersion model (p. 61)
> mj_null <- betareg(confidence ~ 1 | 1, data = MockJurors)
> mj_fd <-   betareg(confidence ~ verdict * conflict | 1, data = MockJurors)
> lrtest(mj_null, mj_fd)
Likelihood ratio test

Model 1: confidence ~ 1 | 1
Model 2: confidence ~ verdict * conflict | 1
  #Df LogLik Df  Chisq Pr(>Chisq)
1   2 28.226                     
2   5 30.580  3 4.7086     0.1944
> lrtest(mj_null, mj_vd)
Likelihood ratio test

Model 1: confidence ~ 1 | 1
Model 2: confidence ~ verdict * conflict | verdict * conflict
  #Df LogLik Df  Chisq Pr(>Chisq)    
1   2 28.226                         
2   8 40.117  6 23.782  0.0005728 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> ## McFadden's pseudo-R-squared
> 1 - as.vector(logLik(mj_null)/logLik(mj_vd))
[1] 0.296407
> 
> ## visualization
> if(require("lattice")) {
+   histogram(~ confidence | conflict + verdict, data = MockJurors,
+     col = "lightgray", breaks = 0:10/10, type = "density")
+ }
Loading required package: lattice
> 
> ## see demo("SmithsonVerkuilen2006", package = "betareg") for more details
> 
> 
> 
> cleanEx()

detaching 'package:lattice', 'package:lmtest', 'package:zoo'

> nameEx("ReadingSkills")
> ### * ReadingSkills
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: ReadingSkills
> ### Title: Dyslexia and IQ Predicting Reading Accuracy
> ### Aliases: ReadingSkills
> ### Keywords: datasets
> 
> ### ** Examples
> 
> data("ReadingSkills", package = "betareg")
> 
> ## Smithson & Verkuilen (2006, Table 5)
> ## OLS regression
> ## (Note: typo in iq coefficient: 0.3954 instead of 0.3594)
> rs_ols <- lm(qlogis(accuracy) ~ dyslexia * iq, data = ReadingSkills)
> summary(rs_ols)

Call:
lm(formula = qlogis(accuracy) ~ dyslexia * iq, data = ReadingSkills)

Residuals:
     Min       1Q   Median       3Q      Max 
-2.66405 -0.37966  0.03687  0.40887  2.50345 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)   1.6011     0.2259   7.089 1.41e-08 ***
dyslexia     -1.2056     0.2259  -5.338 4.01e-06 ***
iq            0.3594     0.2255   1.594   0.1188    
dyslexia:iq  -0.4229     0.2255  -1.875   0.0681 .  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 1.2 on 40 degrees of freedom
Multiple R-squared:  0.6151,	Adjusted R-squared:  0.5862 
F-statistic: 21.31 on 3 and 40 DF,  p-value: 2.083e-08

> ## Beta regression (with numerical rather than analytic standard errors)
> ## (Note: Smithson & Verkuilen erroneously compute one-sided p-values)
> rs_beta <- betareg(accuracy ~ dyslexia * iq | dyslexia + iq,
+   data = ReadingSkills, hessian = TRUE)
> summary(rs_beta)

Call:
betareg(formula = accuracy ~ dyslexia * iq | dyslexia + iq, data = ReadingSkills, 
    hessian = TRUE)

Standardized weighted residuals 2:
    Min      1Q  Median      3Q     Max 
-2.3900 -0.6416  0.1572  0.8524  1.6446 

Coefficients (mean model with logit link):
            Estimate Std. Error z value Pr(>|z|)    
(Intercept)   1.1232     0.1509   7.444 9.76e-14 ***
dyslexia     -0.7416     0.1515  -4.897 9.74e-07 ***
iq            0.4864     0.1671   2.911 0.003603 ** 
dyslexia:iq  -0.5813     0.1726  -3.368 0.000757 ***

Phi coefficients (precision model with log link):
            Estimate Std. Error z value Pr(>|z|)    
(Intercept)   3.3044     0.2265  14.589  < 2e-16 ***
dyslexia      1.7466     0.2940   5.941 2.83e-09 ***
iq            1.2291     0.4596   2.674  0.00749 ** 
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Type of estimator: ML (maximum likelihood)
Log-likelihood:  65.9 on 7 Df
Pseudo R-squared: 0.5756
Number of iterations in BFGS optimization: 25 
> 
> ## visualization
> plot(accuracy ~ iq, data = ReadingSkills, col = as.numeric(dyslexia), pch = 19)
> nd <- data.frame(dyslexia = "no", iq = -30:30/10)
> lines(nd$iq, predict(rs_beta, nd))
> lines(nd$iq, plogis(predict(rs_ols, nd)), lty = 2)
> nd <- data.frame(dyslexia = "yes", iq = -30:30/10)
> lines(nd$iq, predict(rs_beta, nd), col = 2)
> lines(nd$iq, plogis(predict(rs_ols, nd)), col = 2, lty = 2)
> 
> ## see demo("SmithsonVerkuilen2006", package = "betareg") for more details
> 
> 
> 
> cleanEx()
> nameEx("StressAnxiety")
> ### * StressAnxiety
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: StressAnxiety
> ### Title: Dependency of Anxiety on Stress
> ### Aliases: StressAnxiety
> ### Keywords: datasets
> 
> ### ** Examples
> 
> data("StressAnxiety", package = "betareg")
> StressAnxiety <- StressAnxiety[order(StressAnxiety$stress),]
> 
> ## Smithson & Verkuilen (2006, Table 4)
> sa_null <- betareg(anxiety ~ 1 | 1,
+   data = StressAnxiety, hessian = TRUE)
> sa_stress <- betareg(anxiety ~ stress | stress,
+   data = StressAnxiety, hessian = TRUE)
> summary(sa_null)

Call:
betareg(formula = anxiety ~ 1 | 1, data = StressAnxiety, hessian = TRUE)

Standardized weighted residuals 2:
    Min      1Q  Median      3Q     Max 
-0.6806 -0.6806 -0.2705  0.6581  2.0002 

Coefficients (mean model with logit link):
            Estimate Std. Error z value Pr(>|z|)    
(Intercept) -2.24396    0.09879  -22.71   <2e-16 ***

Phi coefficients (precision model with log link):
            Estimate Std. Error z value Pr(>|z|)    
(Intercept)    1.796      0.123    14.6   <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Type of estimator: ML (maximum likelihood)
Log-likelihood: 239.4 on 2 Df
Number of iterations in BFGS optimization: 9 
> summary(sa_stress)

Call:
betareg(formula = anxiety ~ stress | stress, data = StressAnxiety, hessian = TRUE)

Standardized weighted residuals 2:
    Min      1Q  Median      3Q     Max 
-2.3686 -0.6704 -0.0024  0.6213  2.0510 

Coefficients (mean model with logit link):
            Estimate Std. Error z value Pr(>|z|)    
(Intercept)  -4.0237     0.1442  -27.90   <2e-16 ***
stress        4.9414     0.4409   11.21   <2e-16 ***

Phi coefficients (precision model with log link):
            Estimate Std. Error z value Pr(>|z|)    
(Intercept)   3.9608     0.2511  15.776  < 2e-16 ***
stress       -4.2733     0.7532  -5.674  1.4e-08 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Type of estimator: ML (maximum likelihood)
Log-likelihood:   302 on 4 Df
Pseudo R-squared: 0.4748
Number of iterations in BFGS optimization: 16 
> AIC(sa_null, sa_stress)
          df       AIC
sa_null    2 -474.8960
sa_stress  4 -595.9202
> 1 - as.vector(logLik(sa_null)/logLik(sa_stress))
[1] 0.207021
> 
> ## visualization
> attach(StressAnxiety)
> plot(jitter(anxiety) ~ jitter(stress),
+   xlab = "Stress", ylab = "Anxiety",
+   xlim = c(0, 1), ylim = c(0, 1))
> lines(lowess(anxiety ~ stress))
> lines(fitted(sa_stress) ~ stress, lty = 2)
> lines(fitted(lm(anxiety ~ stress)) ~ stress, lty = 3)
> legend("topleft", c("lowess", "betareg", "lm"), lty = 1:3, bty = "n")
> detach(StressAnxiety)
> 
> ## see demo("SmithsonVerkuilen2006", package = "betareg") for more details
> 
> 
> 
> cleanEx()
> nameEx("WeatherTask")
> ### * WeatherTask
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: WeatherTask
> ### Title: Weather Task With Priming and Precise and Imprecise
> ###   Probabilities
> ### Aliases: WeatherTask
> ### Keywords: datasets
> 
> ### ** Examples
> 
> data("WeatherTask", package = "betareg")
> wt_betamix <- betamix(agreement ~ 1, data = WeatherTask, k = 2,
+   extra_components = extraComponent(type = "betareg", coef =
+     list(mean = 0, precision = 2)),
+   FLXconcomitant = FLXPmultinom(~ priming + eliciting))
Loading required package: flexmix
Loading required package: lattice
> 
> 
> 
> cleanEx()

detaching 'package:flexmix', 'package:lattice'

> nameEx("betamix")
> ### * betamix
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: betamix
> ### Title: Finite Mixtures of Beta Regression for Rates and Proportions
> ### Aliases: betamix extraComponent fitted,FLXMRbeta-method
> ###   fitted,betamix-method posterior,betamix,ANY-method
> ###   clusters,betamix,ANY-method predict,FLXMRbeta-method
> ###   predict,FLXMRbetafix-method predict,betamix-method
> ### Keywords: regression cluster
> 
> ### ** Examples
> 
> ## data with two groups of dyslexic and non-dyslexic children
> data("ReadingSkills", package = "betareg")
> 
> set.seed(4040)
> ## try to capture accuracy ~ iq relationship (without using dyslexia
> ## information) using two beta regression components and one additional
> ## extra component for a perfect reading score
> rs_mix <- betamix(accuracy ~ iq, data = ReadingSkills, k = 3,
+   nstart = 10, extra_components = extraComponent(type = "uniform",
+   coef = 0.99, delta = 0.01))
Loading required package: flexmix
Loading required package: lattice
> 
> ## visualize result
> ## intensities based on posterior probabilities
> prob <- 2 * (posterior(rs_mix)[cbind(1:nrow(ReadingSkills),
+    clusters(rs_mix))] - 0.5)
> ## associated HCL colors
> col0 <- hcl(c(260, 0, 130), 65, 45, fixup = FALSE)
> col1 <- col0[clusters(rs_mix)]
> col2 <- hcl(c(260, 0, 130)[clusters(rs_mix)], 65 * abs(prob)^1.5,
+    95 - 50 * abs(prob)^1.5, fixup = FALSE)
> ## scatter plot
> plot(accuracy ~ iq, data = ReadingSkills, col = col2, pch = 19,
+    cex = 1.5, xlim = c(-2, 2))
> points(accuracy ~ iq, data = ReadingSkills, cex = 1.5, pch = 1,
+    col = col1)
> ## fitted lines
> iq <- -30:30/10
> cf <- rbind(coef(rs_mix, model = "mean", component = 1:2),
+    c(qlogis(0.99), 0))
> for(i in 1:3)
+    lines(iq, plogis(cf[i, 1] + cf[i, 2] * iq), lwd = 2,
+          col = col0[i])
> 
> ## refit the model including a concomitant variable model
> ## using the dyslexia information
> w <- rnorm(nrow(ReadingSkills), 
+            c(-1, 1)[as.integer(ReadingSkills$dyslexia)])
> 
> ## The argument FLXconcomitant can be omitted when specifying
> ## the model via a three part formula given by
> ## accuracy ~ iq | 1 | w
> ## The posteriors from the previously fitted model are used
> ## for initialization.
> rs_mix2 <- betamix(accuracy ~ iq, data = ReadingSkills,
+   extra_components = extraComponent(type = "uniform",
+   coef = 0.99, delta = 0.01), cluster = posterior(rs_mix),
+   FLXconcomitant = FLXPmultinom(~w))
> coef(rs_mix2, which = "concomitant")
  (Intercept)          w
1  0.00000000  0.0000000
2  0.41499996  1.0035962
3 -0.09352429 -0.1806346
> summary(rs_mix2, which = "concomitant")
$Comp.2
            Estimate Std. Error z value Pr(>|z|)  
(Intercept)  0.41536    0.64005  0.6490  0.51637  
w            1.00360    0.50781  1.9763  0.04812 *
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

$Comp.3
             Estimate Std. Error z value Pr(>|z|)
(Intercept) -0.093392   0.646390 -0.1445   0.8851
w           -0.180655   0.436804 -0.4136   0.6792

> 
> 
> 
> cleanEx()

detaching 'package:flexmix', 'package:lattice'

> nameEx("betareg")
> ### * betareg
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: betareg
> ### Title: Beta Regression for Rates and Proportions
> ### Aliases: betareg betareg.fit
> ### Keywords: regression
> 
> ### ** Examples
> 
> ## Section 4 from Ferrari and Cribari-Neto (2004)
> data("GasolineYield", package = "betareg")
> data("FoodExpenditure", package = "betareg")
> 
> ## Table 1
> gy <- betareg(yield ~ batch + temp, data = GasolineYield)
> summary(gy)

Call:
betareg(formula = yield ~ batch + temp, data = GasolineYield)

Standardized weighted residuals 2:
    Min      1Q  Median      3Q     Max 
-2.8750 -0.8149  0.1601  0.8384  2.0483 

Coefficients (mean model with logit link):
              Estimate Std. Error z value Pr(>|z|)    
(Intercept) -6.1595710  0.1823247 -33.784  < 2e-16 ***
batch1       1.7277289  0.1012294  17.067  < 2e-16 ***
batch2       1.3225969  0.1179020  11.218  < 2e-16 ***
batch3       1.5723099  0.1161045  13.542  < 2e-16 ***
batch4       1.0597141  0.1023598  10.353  < 2e-16 ***
batch5       1.1337518  0.1035232  10.952  < 2e-16 ***
batch6       1.0401618  0.1060365   9.809  < 2e-16 ***
batch7       0.5436922  0.1091275   4.982 6.29e-07 ***
batch8       0.4959007  0.1089257   4.553 5.30e-06 ***
batch9       0.3857930  0.1185933   3.253  0.00114 ** 
temp         0.0109669  0.0004126  26.577  < 2e-16 ***

Phi coefficients (precision model with identity link):
      Estimate Std. Error z value Pr(>|z|)    
(phi)    440.3      110.0   4.002 6.29e-05 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Type of estimator: ML (maximum likelihood)
Log-likelihood:  84.8 on 12 Df
Pseudo R-squared: 0.9617
Number of iterations: 51 (BFGS) + 3 (Fisher scoring) 
> 
> ## Table 2
> fe_lin <- lm(I(food/income) ~ income + persons, data = FoodExpenditure)
> library("lmtest")
Loading required package: zoo

Attaching package: 'zoo'

The following object is masked from 'package:base':

    as.Date, as.Date.numeric

> bptest(fe_lin)

	studentized Breusch-Pagan test

data:  fe_lin
BP = 5.9348, df = 2, p-value = 0.05144

> fe_beta <- betareg(I(food/income) ~ income + persons, data = FoodExpenditure)
> summary(fe_beta)

Call:
betareg(formula = I(food/income) ~ income + persons, data = FoodExpenditure)

Standardized weighted residuals 2:
    Min      1Q  Median      3Q     Max 
-2.7818 -0.4445  0.2024  0.6852  1.8755 

Coefficients (mean model with logit link):
             Estimate Std. Error z value Pr(>|z|)    
(Intercept) -0.622548   0.223854  -2.781 0.005418 ** 
income      -0.012299   0.003036  -4.052 5.09e-05 ***
persons      0.118462   0.035341   3.352 0.000802 ***

Phi coefficients (precision model with identity link):
      Estimate Std. Error z value Pr(>|z|)    
(phi)    35.61       8.08   4.407 1.05e-05 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Type of estimator: ML (maximum likelihood)
Log-likelihood: 45.33 on 4 Df
Pseudo R-squared: 0.3878
Number of iterations: 28 (BFGS) + 4 (Fisher scoring) 
> 
> ## nested model comparisons via Wald and LR tests
> fe_beta2 <- betareg(I(food/income) ~ income, data = FoodExpenditure)
> lrtest(fe_beta, fe_beta2)
Likelihood ratio test

Model 1: I(food/income) ~ income + persons
Model 2: I(food/income) ~ income
  #Df LogLik Df Chisq Pr(>Chisq)   
1   4 45.334                       
2   3 40.511 -1 9.646   0.001898 **
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> waldtest(fe_beta, fe_beta2)
Wald test

Model 1: I(food/income) ~ income + persons
Model 2: I(food/income) ~ income
  Res.Df Df  Chisq Pr(>Chisq)    
1     34                         
2     35 -1 11.236  0.0008023 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> 
> 
> ## Section 3 from online supplements to Simas et al. (2010)
> ## mean model as in gy above
> ## precision model with regressor temp
> gy2 <- betareg(yield ~ batch + temp | temp, data = GasolineYield)
> 
> ## MLE column in Table 19
> summary(gy2)

Call:
betareg(formula = yield ~ batch + temp | temp, data = GasolineYield)

Standardized weighted residuals 2:
    Min      1Q  Median      3Q     Max 
-2.5399 -0.7792 -0.1167  0.8621  2.9419 

Coefficients (mean model with logit link):
              Estimate Std. Error z value Pr(>|z|)    
(Intercept) -5.9232361  0.1835262 -32.275  < 2e-16 ***
batch1       1.6019877  0.0638561  25.087  < 2e-16 ***
batch2       1.2972663  0.0991001  13.090  < 2e-16 ***
batch3       1.5653383  0.0997392  15.694  < 2e-16 ***
batch4       1.0300720  0.0632882  16.276  < 2e-16 ***
batch5       1.1541630  0.0656427  17.582  < 2e-16 ***
batch6       1.0194446  0.0663510  15.364  < 2e-16 ***
batch7       0.6222591  0.0656325   9.481  < 2e-16 ***
batch8       0.5645830  0.0601846   9.381  < 2e-16 ***
batch9       0.3594390  0.0671406   5.354 8.63e-08 ***
temp         0.0103595  0.0004362  23.751  < 2e-16 ***

Phi coefficients (precision model with log link):
            Estimate Std. Error z value Pr(>|z|)    
(Intercept) 1.364089   1.225781   1.113    0.266    
temp        0.014570   0.003618   4.027 5.65e-05 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Type of estimator: ML (maximum likelihood)
Log-likelihood: 86.98 on 13 Df
Pseudo R-squared: 0.9519
Number of iterations: 33 (BFGS) + 28 (Fisher scoring) 
> 
> ## LRT row in Table 18
> lrtest(gy, gy2)
Likelihood ratio test

Model 1: yield ~ batch + temp
Model 2: yield ~ batch + temp | temp
  #Df LogLik Df Chisq Pr(>Chisq)  
1  12 84.798                      
2  13 86.977  1 4.359    0.03681 *
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> 
> 
> 
> cleanEx()

detaching 'package:lmtest', 'package:zoo'

> nameEx("betareg.control")
> ### * betareg.control
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: betareg.control
> ### Title: Control Parameters for Beta Regression
> ### Aliases: betareg.control
> ### Keywords: regression
> 
> ### ** Examples
> 
> data("GasolineYield", package = "betareg")
> 
> ## regression with phi as full model parameter
> gy1 <- betareg(yield ~ batch + temp, data = GasolineYield)
> gy1

Call:
betareg(formula = yield ~ batch + temp, data = GasolineYield)

Coefficients (mean model with logit link):
(Intercept)       batch1       batch2       batch3       batch4       batch5  
   -6.15957      1.72773      1.32260      1.57231      1.05971      1.13375  
     batch6       batch7       batch8       batch9         temp  
    1.04016      0.54369      0.49590      0.38579      0.01097  

Phi coefficients (precision model with identity link):
(phi)  
440.3  

> 
> ## regression with phi as nuisance parameter
> gy2 <- betareg(yield ~ batch + temp, data = GasolineYield, phi = FALSE)
> gy2

Call:
betareg(formula = yield ~ batch + temp, data = GasolineYield, phi = FALSE)

Coefficients (mean model with logit link):
(Intercept)       batch1       batch2       batch3       batch4       batch5  
   -6.15957      1.72773      1.32260      1.57231      1.05971      1.13375  
     batch6       batch7       batch8       batch9         temp  
    1.04016      0.54369      0.49590      0.38579      0.01097  

> 
> ## compare reported output
> coef(gy1)
 (Intercept)       batch1       batch2       batch3       batch4       batch5 
 -6.15957105   1.72772888   1.32259692   1.57230989   1.05971411   1.13375178 
      batch6       batch7       batch8       batch9         temp        (phi) 
  1.04016181   0.54369223   0.49590066   0.38579296   0.01096687 440.27838856 
> coef(gy2)
(Intercept)      batch1      batch2      batch3      batch4      batch5 
-6.15957105  1.72772888  1.32259692  1.57230989  1.05971411  1.13375178 
     batch6      batch7      batch8      batch9        temp 
 1.04016181  0.54369223  0.49590066  0.38579296  0.01096687 
> summary(gy1)

Call:
betareg(formula = yield ~ batch + temp, data = GasolineYield)

Standardized weighted residuals 2:
    Min      1Q  Median      3Q     Max 
-2.8750 -0.8149  0.1601  0.8384  2.0483 

Coefficients (mean model with logit link):
              Estimate Std. Error z value Pr(>|z|)    
(Intercept) -6.1595710  0.1823247 -33.784  < 2e-16 ***
batch1       1.7277289  0.1012294  17.067  < 2e-16 ***
batch2       1.3225969  0.1179020  11.218  < 2e-16 ***
batch3       1.5723099  0.1161045  13.542  < 2e-16 ***
batch4       1.0597141  0.1023598  10.353  < 2e-16 ***
batch5       1.1337518  0.1035232  10.952  < 2e-16 ***
batch6       1.0401618  0.1060365   9.809  < 2e-16 ***
batch7       0.5436922  0.1091275   4.982 6.29e-07 ***
batch8       0.4959007  0.1089257   4.553 5.30e-06 ***
batch9       0.3857930  0.1185933   3.253  0.00114 ** 
temp         0.0109669  0.0004126  26.577  < 2e-16 ***

Phi coefficients (precision model with identity link):
      Estimate Std. Error z value Pr(>|z|)    
(phi)    440.3      110.0   4.002 6.29e-05 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Type of estimator: ML (maximum likelihood)
Log-likelihood:  84.8 on 12 Df
Pseudo R-squared: 0.9617
Number of iterations: 51 (BFGS) + 3 (Fisher scoring) 
> summary(gy2)

Call:
betareg(formula = yield ~ batch + temp, data = GasolineYield, phi = FALSE)

Standardized weighted residuals 2:
    Min      1Q  Median      3Q     Max 
-2.8750 -0.8149  0.1601  0.8384  2.0483 

Coefficients (mean model with logit link):
              Estimate Std. Error z value Pr(>|z|)    
(Intercept) -6.1595710  0.1823247 -33.784  < 2e-16 ***
batch1       1.7277289  0.1012294  17.067  < 2e-16 ***
batch2       1.3225969  0.1179020  11.218  < 2e-16 ***
batch3       1.5723099  0.1161045  13.542  < 2e-16 ***
batch4       1.0597141  0.1023598  10.353  < 2e-16 ***
batch5       1.1337518  0.1035232  10.952  < 2e-16 ***
batch6       1.0401618  0.1060365   9.809  < 2e-16 ***
batch7       0.5436922  0.1091275   4.982 6.29e-07 ***
batch8       0.4959007  0.1089257   4.553 5.30e-06 ***
batch9       0.3857930  0.1185933   3.253  0.00114 ** 
temp         0.0109669  0.0004126  26.577  < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Type of estimator: ML (maximum likelihood)
Log-likelihood:  84.8 on 12 Df
Pseudo R-squared: 0.9617
Number of iterations: 51 (BFGS) + 3 (Fisher scoring) 
> 
> 
> 
> cleanEx()
> nameEx("betatree")
> ### * betatree
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: betatree
> ### Title: Beta Regression Trees
> ### Aliases: betatree coef.betatree logLik.betatree plot.betatree
> ###   print.betatree sctest.betatree summary.betatree weights.betatree
> ###   betaReg print.betaReg reweight.betaReg summary.betaReg estfun.betaReg
> ### Keywords: tree
> 
> ### ** Examples
> 
> ## data with two groups of dyslexic and non-dyslexic children
> data("ReadingSkills", package = "betareg")
> ## additional random noise (not associated with reading scores)
> set.seed(1071)
> ReadingSkills$x1 <- rnorm(nrow(ReadingSkills))
> ReadingSkills$x2 <- runif(nrow(ReadingSkills))
> ReadingSkills$x3 <- factor(rnorm(nrow(ReadingSkills)) > 0)
> 
> ## fit beta regression tree: in each node
> ##   - accurcay's mean and precision depends on iq
> ##   - partitioning is done by dyslexia and the noise variables x1, x2, x3
> ## only dyslexi is correctly selected for splitting
> bt <- betatree(accuracy ~ iq | iq, ~ dyslexia + x1 + x2 + x3,
+   data = ReadingSkills, minsplit = 10)
Loading required package: party
Loading required package: survival
Loading required package: splines
Loading required package: grid
Loading required package: modeltools
Loading required package: stats4
Loading required package: coin
Loading required package: mvtnorm
Loading required package: zoo

Attaching package: 'zoo'

The following object is masked from 'package:base':

    as.Date, as.Date.numeric

Loading required package: sandwich
Loading required package: strucchange
Loading required package: vcd
Loading required package: MASS
Loading required package: colorspace
> plot(bt)
> 
> ## inspect result
> coef(bt)
  (Intercept)          iq (phi)_(Intercept)  (phi)_iq
2   1.6565251  1.46570751          1.272597 2.0478578
3   0.3809322 -0.08622808          4.807662 0.8260329
> sctest(bt)
$`1`
              dyslexia        x1       x2        x3
statistic 2.268741e+01 8.5250962 5.569861 1.0567635
p.value   5.847856e-04 0.9094631 0.998710 0.9999042

$`2`
          dyslexia        x1        x2        x3
statistic        0 6.4116324 4.5170190 4.2308113
p.value         NA 0.8412097 0.9751644 0.7566428

$`3`
          [,1]
statistic    0
p.value      1

> summary(bt, node = 2)

Call:
NULL

Raw response residuals:
    Min      1Q  Median      3Q     Max 
-0.3975 -0.1247  0.0043  0.1149  0.4114 

Coefficients (mean model with logit link):
            Estimate Std. Error z value Pr(>|z|)    
(Intercept)   1.6565     0.2864   5.785 7.27e-09 ***
iq            1.4657     0.2475   5.921 3.20e-09 ***

Phi coefficients (precision model with log link):
            Estimate Std. Error z value Pr(>|z|)    
(Intercept)   1.2726     0.3068   4.148 3.36e-05 ***
iq            2.0479     0.3306   6.194 5.85e-10 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Type of estimator: ML (maximum likelihood)
Log-likelihood: 39.41 on 4 Df
Pseudo R-squared: 0.3292
Number of iterations: 17 (BFGS) + 1 (Fisher scoring) 
> summary(bt, node = 3)

Call:
NULL

Raw response residuals:
    Min      1Q  Median      3Q     Max 
-0.1512  0.0170  0.1032  0.3925  0.4350 

Coefficients (mean model with logit link):
            Estimate Std. Error z value Pr(>|z|)    
(Intercept)  0.38093    0.04863   7.833 4.76e-15 ***
iq          -0.08623    0.05492  -1.570    0.116    

Phi coefficients (precision model with log link):
            Estimate Std. Error z value Pr(>|z|)    
(Intercept)   4.8077     0.4142  11.607   <2e-16 ***
iq            0.8260     0.3946   2.093   0.0363 *  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Type of estimator: ML (maximum likelihood)
Log-likelihood: 27.33 on 4 Df
Pseudo R-squared: 0.3292
Number of iterations: 19 (BFGS) + 8 (Fisher scoring) 
> 
> ## add a numerical variable with relevant information for splitting
> ReadingSkills$x4 <- rnorm(nrow(ReadingSkills), c(-1.5, 1.5)[ReadingSkills$dyslexia])
> 
> bt2 <- betatree(accuracy ~ iq | iq, ~ x1 + x2 + x3 + x4,
+   data = ReadingSkills, minsplit = 10)
> plot(bt2)
> 
> ## inspect result
> coef(bt2)
  (Intercept)         iq (phi)_(Intercept)   (phi)_iq
2   1.7060360 1.47402394          1.293303  2.0840962
3   0.5047507 0.03390671          3.131115 -0.7683503
> sctest(bt2)
$`1`
                 x1       x2        x3          x4
statistic 8.5250962 5.569861 1.0567635 19.94405064
p.value   0.9094631 0.998710 0.9999042  0.03531254

$`2`
                 x1       x2       x3        x4
statistic 8.9466724 3.588752 3.567712 4.7049445
p.value   0.5964143 0.998549 0.919691 0.9848264

$`3`
          x1 x2        x3 x4
statistic  0  0 4.8649075  0
p.value   NA NA 0.3014418 NA

> summary(bt2, node = 2)

Call:
NULL

Raw response residuals:
    Min      1Q  Median      3Q     Max 
-0.3995 -0.1325  0.0034  0.1058  0.4013 

Coefficients (mean model with logit link):
            Estimate Std. Error z value Pr(>|z|)    
(Intercept)   1.7060     0.2916   5.850 4.92e-09 ***
iq            1.4740     0.2478   5.948 2.72e-09 ***

Phi coefficients (precision model with log link):
            Estimate Std. Error z value Pr(>|z|)    
(Intercept)   1.2933     0.3120   4.145 3.40e-05 ***
iq            2.0841     0.3333   6.253 4.03e-10 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Type of estimator: ML (maximum likelihood)
Log-likelihood: 38.62 on 4 Df
Pseudo R-squared: 0.3292
Number of iterations: 17 (BFGS) + 2 (Fisher scoring) 
> summary(bt2, node = 3)

Call:
NULL

Raw response residuals:
    Min      1Q  Median      3Q     Max 
-0.1579  0.0057  0.0904  0.3525  0.3737 

Coefficients (mean model with logit link):
            Estimate Std. Error z value Pr(>|z|)    
(Intercept)  0.50475    0.12449   4.054 5.02e-05 ***
iq           0.03391    0.09980   0.340    0.734    

Phi coefficients (precision model with log link):
            Estimate Std. Error z value Pr(>|z|)    
(Intercept)   3.1311     0.3704   8.454   <2e-16 ***
iq           -0.7684     0.3591  -2.140   0.0324 *  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Type of estimator: ML (maximum likelihood)
Log-likelihood: 22.38 on 4 Df
Pseudo R-squared: 0.3292
Number of iterations: 18 (BFGS) + 1 (Fisher scoring) 
> 
> 
> 
> 
> cleanEx()

detaching 'package:party', 'package:vcd', 'package:colorspace',
  'package:MASS', 'package:strucchange', 'package:sandwich',
  'package:zoo', 'package:coin', 'package:mvtnorm',
  'package:modeltools', 'package:stats4', 'package:grid',
  'package:survival', 'package:splines'

> nameEx("gleverage")
> ### * gleverage
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: gleverage
> ### Title: Generalized Leverage Values
> ### Aliases: gleverage gleverage.betareg
> ### Keywords: regression
> 
> ### ** Examples
> 
> data("GasolineYield", package = "betareg")
> gy <- betareg(yield ~ batch + temp, data = GasolineYield)
> gleverage(gy)
        1         2         3         4         5         6         7         8 
0.2166653 0.2516981 0.3253746 0.4541676 0.2239175 0.3200751 0.5271369 0.2818832 
        9        10        11        12        13        14        15        16 
0.3010917 0.5065938 0.1969837 0.2145541 0.3053700 0.4396677 0.2908692 0.3514349 
       17        18        19        20        21        22        23        24 
0.4049314 0.2448004 0.3569878 0.4840069 0.2154146 0.1834851 0.2899263 0.4700661 
       25        26        27        28        29        30        31        32 
0.2909617 0.2982017 0.5448905 0.3677161 0.6602709 0.3181028 0.2557126 0.4569484 
> 
> 
> 
> cleanEx()
> nameEx("plot.betareg")
> ### * plot.betareg
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: plot.betareg
> ### Title: Diagnostic Plots for betareg Objects
> ### Aliases: plot.betareg
> ### Keywords: regression
> 
> ### ** Examples
> 
> data("GasolineYield", package = "betareg")
> 
> gy <- betareg(yield ~ gravity + pressure + temp10 + temp, data = GasolineYield)
> 
> par(mfrow = c(3, 2))
> plot(gy, which = 1:6)
> par(mfrow = c(1, 1))
> 
> 
> 
> graphics::par(get("par.postscript", pos = 'CheckExEnv'))
> cleanEx()
> nameEx("predict.betareg")
> ### * predict.betareg
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: predict.betareg
> ### Title: Prediction Method for betareg Objects
> ### Aliases: predict.betareg
> ### Keywords: regression
> 
> ### ** Examples
> 
> data("GasolineYield", package = "betareg")
> 
> gy2 <- betareg(yield ~ batch + temp | temp, data = GasolineYield)
> 
> cbind(
+   predict(gy2, type = "response"),
+   predict(gy2, type = "link"),
+   predict(gy2, type = "precision"),
+   predict(gy2, type = "variance"),
+   predict(gy2, type = "quantile", at = c(0.25, 0.5, 0.75))
+ )
                                                     q_0.25      q_0.5
1  0.09997030 -2.1975546   77.55630 1.145373e-03 0.07549306 0.09653422
2  0.18657948 -1.4723909  215.06200 7.024260e-04 0.16816141 0.18560681
3  0.32142578 -0.7472272  596.36246 3.651238e-04 0.30841729 0.32122603
4  0.47378921 -0.1049393 1471.75136 1.692838e-04 0.46500324 0.47377734
5  0.08567673 -2.3676029   93.72999 8.269423e-04 0.06489692 0.08273480
6  0.14211525 -1.7978314  208.88539 5.808814e-04 0.12524873 0.14097226
7  0.26284576 -1.0312297  613.99653 3.150552e-04 0.25072516 0.26258813
8  0.10324409 -2.1616877   85.88389 1.065615e-03 0.07972496 0.10016550
9  0.17651800 -1.5401188  205.86393 7.026812e-04 0.15805951 0.17546930
10 0.30244665 -0.8356741  554.46132 3.798152e-04 0.28916034 0.30220897
11 0.07880568 -2.4586860  120.07465 5.995916e-04 0.06118775 0.07647135
12 0.14364751 -1.7853197  309.57002 3.960875e-04 0.12981151 0.14287972
13 0.24750690 -1.1119533  798.11684 2.330663e-04 0.23708990 0.24729591
14 0.34394188 -0.6457767 1537.50973 1.466652e-04 0.33573361 0.34387420
15 0.16956516 -1.5887122  342.81006 4.095657e-04 0.15556251 0.16892216
16 0.27545027 -0.9671433  821.71666 2.425834e-04 0.26483999 0.27526801
17 0.33691381 -0.6770778 1235.66499 1.806495e-04 0.32779629 0.33682580
18 0.10547585 -2.1378099  191.39968 4.903890e-04 0.08983849 0.10410171
19 0.23606454 -1.1743781  742.04019 2.427030e-04 0.22542250 0.23582731
20 0.32316164 -0.7392798 1368.34435 1.597321e-04 0.31458683 0.32307546
21 0.05383471 -2.8664989  120.07465 4.207035e-04 0.03892848 0.05136993
22 0.07928368 -2.4521196  215.06200 3.378557e-04 0.06624459 0.07798069
23 0.16906299 -1.5922826  720.72869 1.946447e-04 0.15948521 0.16875678
24 0.27062919 -0.9914327 1677.97206 1.175654e-04 0.26326427 0.27053804
25 0.08270107 -2.4062009  248.79507 3.036954e-04 0.07038929 0.08158360
26 0.17115802 -1.5774423  798.11684 1.775247e-04 0.16202069 0.17088326
27 0.31885402 -0.7590433 2523.26796 8.603925e-05 0.31257024 0.31880615
28 0.12701435 -1.9276191  650.84437 1.701046e-04 0.11801311 0.12663223
29 0.23660619 -1.1713769 1885.41604 9.574966e-05 0.22995419 0.23651304
30 0.10507878 -2.1420253  798.11684 1.176764e-04 0.09758762 0.10474890
31 0.11951904 -1.9969926  978.71400 1.074132e-04 0.11239006 0.11925985
32 0.18401511 -1.4893780 1998.56571 7.509308e-05 0.17811235 0.18390969
       q_0.75
1  0.12074136
2  0.20394068
3  0.33421676
4  0.48256225
5  0.10327886
6  0.15774019
7  0.27468582
8  0.12343883
9  0.19383720
10 0.31547416
11 0.09389756
12 0.15664851
13 0.25769409
14 0.35207641
15 0.18286831
16 0.28586202
17 0.34593544
18 0.11962147
19 0.24644820
20 0.33164255
21 0.06607706
22 0.09090812
23 0.17830729
24 0.27789478
25 0.09379888
26 0.17999609
27 0.32508563
28 0.13559952
29 0.24315669
30 0.11221069
31 0.12636570
32 0.18980299
> 
> 
> 
> cleanEx()
> nameEx("residuals.betareg")
> ### * residuals.betareg
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: residuals.betareg
> ### Title: Residuals Method for betareg Objects
> ### Aliases: residuals.betareg
> ### Keywords: regression
> 
> ### ** Examples
> 
> data("GasolineYield", package = "betareg")
> 
> gy <- betareg(yield ~ gravity + pressure + temp10 + temp, data = GasolineYield)
> 
> gy_res <- cbind(
+   residuals(gy, type = "pearson"),
+   residuals(gy, type = "deviance"),
+   residuals(gy, type = "response"),
+   residuals(gy, type = "weighted"),
+   residuals(gy, type = "sweighted"),
+   residuals(gy, type = "sweighted2")
+ )
> colnames(gy_res) <- c("pearson", "deviance", "response",
+   "weighted", "sweighted", "sweighted2")
> pairs(gy_res)
> 
> 
> 
> cleanEx()
> nameEx("summary.betareg")
> ### * summary.betareg
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: summary.betareg
> ### Title: Methods for betareg Objects
> ### Aliases: print.betareg summary.betareg print.summary.betareg
> ###   coef.betareg vcov.betareg bread.betareg estfun.betareg
> ###   coeftest.betareg logLik.betareg terms.betareg model.frame.betareg
> ###   model.matrix.betareg cooks.distance.betareg hatvalues.betareg
> ### Keywords: regression
> 
> ### ** Examples
> 
> data("GasolineYield", package = "betareg")
> 
> gy2 <- betareg(yield ~ batch + temp | temp, data = GasolineYield)
> 
> summary(gy2)

Call:
betareg(formula = yield ~ batch + temp | temp, data = GasolineYield)

Standardized weighted residuals 2:
    Min      1Q  Median      3Q     Max 
-2.5399 -0.7792 -0.1167  0.8621  2.9419 

Coefficients (mean model with logit link):
              Estimate Std. Error z value Pr(>|z|)    
(Intercept) -5.9232361  0.1835262 -32.275  < 2e-16 ***
batch1       1.6019877  0.0638561  25.087  < 2e-16 ***
batch2       1.2972663  0.0991001  13.090  < 2e-16 ***
batch3       1.5653383  0.0997392  15.694  < 2e-16 ***
batch4       1.0300720  0.0632882  16.276  < 2e-16 ***
batch5       1.1541630  0.0656427  17.582  < 2e-16 ***
batch6       1.0194446  0.0663510  15.364  < 2e-16 ***
batch7       0.6222591  0.0656325   9.481  < 2e-16 ***
batch8       0.5645830  0.0601846   9.381  < 2e-16 ***
batch9       0.3594390  0.0671406   5.354 8.63e-08 ***
temp         0.0103595  0.0004362  23.751  < 2e-16 ***

Phi coefficients (precision model with log link):
            Estimate Std. Error z value Pr(>|z|)    
(Intercept) 1.364089   1.225781   1.113    0.266    
temp        0.014570   0.003618   4.027 5.65e-05 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Type of estimator: ML (maximum likelihood)
Log-likelihood: 86.98 on 13 Df
Pseudo R-squared: 0.9519
Number of iterations: 33 (BFGS) + 28 (Fisher scoring) 
> coef(gy2)
      (Intercept)            batch1            batch2            batch3 
      -5.92323614        1.60198775        1.29726625        1.56533827 
           batch4            batch5            batch6            batch7 
       1.03007197        1.15416304        1.01944465        0.62225905 
           batch8            batch9              temp (phi)_(Intercept) 
       0.56458300        0.35943898        0.01035948        1.36408882 
       (phi)_temp 
       0.01457032 
> vcov(gy2)
                    (Intercept)        batch1        batch2        batch3
(Intercept)        3.368188e-02 -4.124178e-03 -8.215820e-03 -8.839188e-03
batch1            -4.124178e-03  4.077605e-03  2.483329e-03  2.523526e-03
batch2            -8.215820e-03  2.483329e-03  9.820824e-03  3.401445e-03
batch3            -8.839188e-03  2.523526e-03  3.401445e-03  9.947910e-03
batch4            -3.672320e-03  2.189276e-03  2.395371e-03  2.426640e-03
batch5            -4.461204e-03  2.239903e-03  2.547611e-03  2.594482e-03
batch6            -3.901967e-03  2.203942e-03  2.439481e-03  2.475300e-03
batch7            -3.007120e-03  2.146456e-03  2.266844e-03  2.284945e-03
batch8            -6.258965e-04  1.992614e-03  1.803596e-03  1.774813e-03
batch9            -1.801331e-03  2.068213e-03  2.031252e-03  2.025655e-03
temp              -7.752898e-05  4.999128e-06  1.503982e-05  1.656923e-05
(phi)_(Intercept) -1.859927e-02  1.681534e-04  9.769192e-04  1.420024e-03
(phi)_temp         4.618253e-05  2.068517e-07 -1.937019e-06 -2.948183e-06
                         batch4        batch5        batch6        batch7
(Intercept)       -3.672320e-03 -4.461204e-03 -3.901967e-03 -3.007120e-03
batch1             2.189276e-03  2.239903e-03  2.203942e-03  2.146456e-03
batch2             2.395371e-03  2.547611e-03  2.439481e-03  2.266844e-03
batch3             2.426640e-03  2.594482e-03  2.475300e-03  2.284945e-03
batch4             4.005400e-03  2.205844e-03  2.177861e-03  2.133142e-03
batch5             2.205844e-03  4.308969e-03  2.223056e-03  2.155852e-03
batch6             2.177861e-03  2.223056e-03  4.402457e-03  2.139678e-03
batch7             2.133142e-03  2.155852e-03  2.139678e-03  4.307625e-03
batch8             2.013379e-03  1.976826e-03  2.002711e-03  2.044120e-03
batch9             2.072227e-03  2.065082e-03  2.070137e-03  2.078208e-03
temp               3.890765e-06  5.826640e-06  4.454355e-06  2.258686e-06
(phi)_(Intercept)  1.408927e-04  1.011239e-03  5.044879e-04 -4.522516e-04
(phi)_temp         6.530191e-08 -2.184587e-06 -8.969410e-07  1.470129e-06
                         batch8        batch9          temp (phi)_(Intercept)
(Intercept)       -6.258965e-04 -1.801331e-03 -7.752898e-05     -1.859927e-02
batch1             1.992614e-03  2.068213e-03  4.999128e-06      1.681534e-04
batch2             1.803596e-03  2.031252e-03  1.503982e-05      9.769192e-04
batch3             1.774813e-03  2.025655e-03  1.656923e-05      1.420024e-03
batch4             2.013379e-03  2.072227e-03  3.890765e-06      1.408927e-04
batch5             1.976826e-03  2.065082e-03  5.826640e-06      1.011239e-03
batch6             2.002711e-03  2.070137e-03  4.454355e-06      5.044879e-04
batch7             2.044120e-03  2.078208e-03  2.258686e-06     -4.522516e-04
batch8             3.622190e-03  2.099718e-03 -3.584650e-06     -1.307067e-03
batch9             2.099718e-03  4.507858e-03 -7.000127e-07     -3.532699e-04
temp              -3.584650e-06 -7.000127e-07  1.902439e-07      4.666494e-05
(phi)_(Intercept) -1.307067e-03 -3.532699e-04  4.666494e-05      1.502540e+00
(phi)_temp         3.674776e-06  1.118606e-06 -1.174672e-07     -4.342353e-03
                     (phi)_temp
(Intercept)        4.618253e-05
batch1             2.068517e-07
batch2            -1.937019e-06
batch3            -2.948183e-06
batch4             6.530191e-08
batch5            -2.184587e-06
batch6            -8.969410e-07
batch7             1.470129e-06
batch8             3.674776e-06
batch9             1.118606e-06
temp              -1.174672e-07
(phi)_(Intercept) -4.342353e-03
(phi)_temp         1.309198e-05
> logLik(gy2)
'log Lik.' 86.97707 (df=13)
> AIC(gy2)
[1] -147.9541
> 
> coef(gy2, model = "mean")
(Intercept)      batch1      batch2      batch3      batch4      batch5 
-5.92323614  1.60198775  1.29726625  1.56533827  1.03007197  1.15416304 
     batch6      batch7      batch8      batch9        temp 
 1.01944465  0.62225905  0.56458300  0.35943898  0.01035948 
> coef(gy2, model = "precision")
(Intercept)        temp 
 1.36408882  0.01457032 
> summary(gy2, phi = FALSE)

Call:
betareg(formula = yield ~ batch + temp | temp, data = GasolineYield)

Standardized weighted residuals 2:
    Min      1Q  Median      3Q     Max 
-2.5399 -0.7792 -0.1167  0.8621  2.9419 

Coefficients (mean model with logit link):
              Estimate Std. Error z value Pr(>|z|)    
(Intercept) -5.9232361  0.1835262 -32.275  < 2e-16 ***
batch1       1.6019877  0.0638561  25.087  < 2e-16 ***
batch2       1.2972663  0.0991001  13.090  < 2e-16 ***
batch3       1.5653383  0.0997392  15.694  < 2e-16 ***
batch4       1.0300720  0.0632882  16.276  < 2e-16 ***
batch5       1.1541630  0.0656427  17.582  < 2e-16 ***
batch6       1.0194446  0.0663510  15.364  < 2e-16 ***
batch7       0.6222591  0.0656325   9.481  < 2e-16 ***
batch8       0.5645830  0.0601846   9.381  < 2e-16 ***
batch9       0.3594390  0.0671406   5.354 8.63e-08 ***
temp         0.0103595  0.0004362  23.751  < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Type of estimator: ML (maximum likelihood)
Log-likelihood: 86.98 on 13 Df
Pseudo R-squared: 0.9519
Number of iterations: 33 (BFGS) + 28 (Fisher scoring) 
> 
> 
> 
> ### * <FOOTER>
> ###
> base::cat("Time elapsed: ", proc.time() - base::get("ptime", pos = 'CheckExEnv'),"\n")
Time elapsed:  48.771 0.188 49.152 0 0 
> grDevices::dev.off()
null device 
          1 
> ###
> ### Local variables: ***
> ### mode: outline-minor ***
> ### outline-regexp: "\\(> \\)?### [*]+" ***
> ### End: ***
> quit('no')
